{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:/Users/08014.surya/Documents/Surya Files/Coba Analysis/Timnas1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              komentar    label\n",
      "0    <username> Simulasi indonesia kembali dijajah ...  negatif\n",
      "1    <username> <username> <username> keturunan lai...  negatif\n",
      "2    <username> <username> uda botak keturunan penj...  negatif\n",
      "3    <username> <username> <username> Belum tentu, ...  negatif\n",
      "4    <username> <username> <username> Lu nya aja yg...  negatif\n",
      "..                                                 ...      ...\n",
      "393  <username> <username> 3 tahun lalu indonesia m...  positif\n",
      "394                                                  \\  positif\n",
      "395  Naturalisasi pemain keturunan menjadi langkah ...  positif\n",
      "396  semua persyaratan yang diperlukan untuk proses...  positif\n",
      "397  <username> Mau percaya sama akmal aja udah ane...  positif\n",
      "\n",
      "[398 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "data = pd.read_csv(file_path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Daftar stop words bahasa Indonesia\n",
    "stop_words_indonesia = [\n",
    "    \"yang\", \"untuk\", \"dengan\", \"dan\", \"pada\", \"ini\", \"itu\", \"di\", \"ke\", \"dari\", \"adalah\",\n",
    "    \"atau\", \"sebagai\", \"dalam\", \"juga\", \"akan\", \"tersebut\", \"mereka\", \"kami\", \"kita\",\n",
    "    \"sudah\", \"belum\", \"bisa\", \"tidak\", \"harus\", \"akan\", \"ada\", \"karena\", \"saja\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Proses pra-pengolahan teks (cleansing data)\n",
    "def clean_text(text):\n",
    "    # Menghapus username dan karakter/simbol/emot\n",
    "    text = text.replace(\"<username>\", \"\").replace(\"\\\\\", \"\").strip()\n",
    "    return text\n",
    "\n",
    "data['komentar'] = data['komentar'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah teks ke representasi numerik dengan CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=stop_words_indonesia)\n",
    "X = vectorizer.fit_transform(data['komentar'])\n",
    "y = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latih model Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi data uji\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.7125\n",
      "Laporan Klasifikasi:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.78      0.66      0.72        44\n",
      "     positif       0.65      0.78      0.71        36\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.72      0.72      0.71        80\n",
      "weighted avg       0.72      0.71      0.71        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hasil evaluasi\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komentar: Indonesia luar biasa! -> Sentimen: positif\n",
      "Komentar: Keturunan penjajah tidak pantas -> Sentimen: negatif\n"
     ]
    }
   ],
   "source": [
    "# Coba Model\n",
    "contoh_komentar = [\"Indonesia luar biasa!\", \"Keturunan penjajah tidak pantas\"]\n",
    "contoh_vector = vectorizer.transform(contoh_komentar)\n",
    "prediksi = model.predict(contoh_vector)\n",
    "\n",
    "for komentar, label in zip(contoh_komentar, prediksi):\n",
    "    print(f\"Komentar: {komentar} -> Sentimen: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Hasil Model\n",
    "\n",
    "1. **Akurasi Model (71.25%)**:  \n",
    "   - Model berhasil memprediksi sentimen dengan tingkat akurasi yang cukup baik, yaitu **71.25%**. Ini menunjukkan bahwa model bisa mengklasifikasikan sekitar 71 dari 100 komentar dengan benar ke dalam kategori `positif` atau `negatif`.\n",
    "\n",
    "2. **Evaluasi Berdasarkan Precision, Recall, dan F1-Score**:\n",
    "   - **Precision**: \n",
    "     - Untuk sentimen **negatif**, precision adalah **0.78**, berarti dari semua prediksi negatif, 78% benar-benar negatif.\n",
    "     - Untuk sentimen **positif**, precision adalah **0.65**, menunjukkan ada sedikit kesalahan dalam memprediksi komentar positif.\n",
    "   - **Recall**:\n",
    "     - Recall untuk sentimen **negatif** adalah **0.66**, artinya model hanya menangkap 66% dari semua komentar negatif yang sebenarnya.\n",
    "     - Recall untuk sentimen **positif** adalah **0.78**, menunjukkan model lebih baik dalam mengidentifikasi komentar positif.\n",
    "   - **F1-Score**:\n",
    "     - Skor **F1** untuk kedua kelas hampir seimbang, yaitu **0.72** untuk negatif dan **0.71** untuk positif. Ini menunjukkan kinerja keseluruhan yang cukup stabil untuk kedua kategori sentimen.\n",
    "\n",
    "3. **Macro Avg vs Weighted Avg**:\n",
    "   - **Macro Avg (0.72)** memberikan rata-rata sederhana antara metrik untuk kedua kelas, tanpa mempertimbangkan distribusi data.\n",
    "   - **Weighted Avg (0.71)** memperhitungkan jumlah sampel di setiap kelas. Nilai yang sedikit lebih rendah menunjukkan ketidakseimbangan data antara kategori `negatif` dan `positif`.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretasi Contoh Prediksi\n",
    "\n",
    "- **Komentar: \"Indonesia luar biasa!\"**  \n",
    "  Prediksi: **positif**  \n",
    "  Analisis: Model berhasil mengidentifikasi kata-kata seperti *luar biasa* yang biasanya dikaitkan dengan sentimen positif.\n",
    "\n",
    "- **Komentar: \"Keturunan penjajah tidak pantas\"**  \n",
    "  Prediksi: **negatif**  \n",
    "  Analisis: Kata-kata seperti *tidak pantas* memiliki konotasi negatif, sehingga model mampu menangkap konteks ini dengan benar.\n",
    "\n",
    "---\n",
    "\n",
    "### Kesimpulan dan Saran\n",
    "\n",
    "1. **Kesimpulan**:\n",
    "   - Model menunjukkan kinerja yang cukup baik, terutama pada kategori sentimen negatif.\n",
    "   - Ada potensi untuk meningkatkan identifikasi komentar positif, seperti yang terlihat dari precision yang lebih rendah (0.65).\n",
    "\n",
    "2. **Saran Perbaikan**:\n",
    "   - **Imbangi Data**: Jika memungkinkan, tambahkan lebih banyak komentar positif untuk melatih model sehingga distribusi data menjadi lebih seimbang.\n",
    "   - **Pengayaan Stop Words**: Perluas daftar stop words untuk menghapus kata-kata umum yang kurang relevan.\n",
    "   - **Gunakan Teknik NLP Lanjutan**: Gunakan model berbasis *embedding* seperti Word2Vec atau BERT untuk menangkap konteks yang lebih dalam.\n",
    "\n",
    "3. **Praktis untuk Aplikasi**:\n",
    "   - Dengan akurasi **71.25%**, model sudah cukup layak untuk analisis sentimen dasar, seperti memantau opini publik terhadap timnas Indonesia di era STY. Namun, untuk penggunaan di industri, kinerja ini masih perlu ditingkatkan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

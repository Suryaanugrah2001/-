{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suryaanugrah2001/-/blob/main/Analisis_sentimen_timnas_Indonesia_di_era_STY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yGEF5bxn-5L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHx6EoGxn-5P"
      },
      "outputs": [],
      "source": [
        "file_path = r\"C:/Users/08014.surya/Documents/Surya Files/Coba Analysis/Timnas1.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFUk97fHn-5P",
        "outputId": "c3d5752e-4d4b-4a52-b6df-46008d742b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              komentar    label\n",
            "0    <username> Simulasi indonesia kembali dijajah ...  negatif\n",
            "1    <username> <username> <username> keturunan lai...  negatif\n",
            "2    <username> <username> uda botak keturunan penj...  negatif\n",
            "3    <username> <username> <username> Belum tentu, ...  negatif\n",
            "4    <username> <username> <username> Lu nya aja yg...  negatif\n",
            "..                                                 ...      ...\n",
            "393  <username> <username> 3 tahun lalu indonesia m...  positif\n",
            "394                                                  \\  positif\n",
            "395  Naturalisasi pemain keturunan menjadi langkah ...  positif\n",
            "396  semua persyaratan yang diperlukan untuk proses...  positif\n",
            "397  <username> Mau percaya sama akmal aja udah ane...  positif\n",
            "\n",
            "[398 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Import Data\n",
        "data = pd.read_csv(file_path)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld5ybSMdn-5R"
      },
      "outputs": [],
      "source": [
        "# Buat Daftar stop words bahasa Indonesia\n",
        "stop_words_indonesia = [\n",
        "    \"yang\", \"untuk\", \"dengan\", \"dan\", \"pada\", \"ini\", \"itu\", \"di\", \"ke\", \"dari\", \"adalah\",\n",
        "    \"atau\", \"sebagai\", \"dalam\", \"juga\", \"akan\", \"tersebut\", \"mereka\", \"kami\", \"kita\",\n",
        "    \"sudah\", \"belum\", \"bisa\", \"tidak\", \"harus\", \"akan\", \"ada\", \"karena\", \"saja\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzhUg8u9n-5S"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Proses pra-pengolahan teks (cleansing data)\n",
        "def clean_text(text):\n",
        "    # Menghapus username dan karakter/simbol/emot\n",
        "    text = text.replace(\"<username>\", \"\").replace(\"\\\\\", \"\").strip()\n",
        "    return text\n",
        "\n",
        "data['komentar'] = data['komentar'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBIWwMPan-5S"
      },
      "outputs": [],
      "source": [
        "# Mengubah teks ke representasi numerik dengan CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words=stop_words_indonesia)\n",
        "X = vectorizer.fit_transform(data['komentar'])\n",
        "y = data['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3EgCbcUn-5S"
      },
      "outputs": [],
      "source": [
        "# bagi dataset menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tA3nlY8n-5T",
        "outputId": "a383258d-4d1d-48ed-b3bc-4f44034fa3e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Latih model Naive Bayes\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIiADqtcn-5T"
      },
      "outputs": [],
      "source": [
        "# prediksi data uji\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S2h5-o-n-5U",
        "outputId": "559a17d6-16d0-483d-e449-5ee6f7589fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi: 0.7125\n",
            "Laporan Klasifikasi:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.78      0.66      0.72        44\n",
            "     positif       0.65      0.78      0.71        36\n",
            "\n",
            "    accuracy                           0.71        80\n",
            "   macro avg       0.72      0.72      0.71        80\n",
            "weighted avg       0.72      0.71      0.71        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# hasil evaluasi\n",
        "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVWuh_Z-n-5U",
        "outputId": "34c54817-f3f1-44c0-f215-19dab0839c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Komentar: Indonesia luar biasa! -> Sentimen: positif\n",
            "Komentar: Keturunan penjajah tidak pantas -> Sentimen: negatif\n"
          ]
        }
      ],
      "source": [
        "# Coba Model\n",
        "contoh_komentar = [\"Indonesia luar biasa!\", \"Keturunan penjajah tidak pantas\"]\n",
        "contoh_vector = vectorizer.transform(contoh_komentar)\n",
        "prediksi = model.predict(contoh_vector)\n",
        "\n",
        "for komentar, label in zip(contoh_komentar, prediksi):\n",
        "    print(f\"Komentar: {komentar} -> Sentimen: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6EVaHc_n-5U"
      },
      "source": [
        "### Analisis Hasil Model\n",
        "\n",
        "1. **Akurasi Model (71.25%)**:  \n",
        "   - Model berhasil memprediksi sentimen dengan tingkat akurasi yang cukup baik, yaitu **71.25%**. Ini menunjukkan bahwa model bisa mengklasifikasikan sekitar 71 dari 100 komentar dengan benar ke dalam kategori `positif` atau `negatif`.\n",
        "\n",
        "2. **Evaluasi Berdasarkan Precision, Recall, dan F1-Score**:\n",
        "   - **Precision**:\n",
        "     - Untuk sentimen **negatif**, precision adalah **0.78**, berarti dari semua prediksi negatif, 78% benar-benar negatif.\n",
        "     - Untuk sentimen **positif**, precision adalah **0.65**, menunjukkan ada sedikit kesalahan dalam memprediksi komentar positif.\n",
        "   - **Recall**:\n",
        "     - Recall untuk sentimen **negatif** adalah **0.66**, artinya model hanya menangkap 66% dari semua komentar negatif yang sebenarnya.\n",
        "     - Recall untuk sentimen **positif** adalah **0.78**, menunjukkan model lebih baik dalam mengidentifikasi komentar positif.\n",
        "   - **F1-Score**:\n",
        "     - Skor **F1** untuk kedua kelas hampir seimbang, yaitu **0.72** untuk negatif dan **0.71** untuk positif. Ini menunjukkan kinerja keseluruhan yang cukup stabil untuk kedua kategori sentimen.\n",
        "\n",
        "3. **Macro Avg vs Weighted Avg**:\n",
        "   - **Macro Avg (0.72)** memberikan rata-rata sederhana antara metrik untuk kedua kelas, tanpa mempertimbangkan distribusi data.\n",
        "   - **Weighted Avg (0.71)** memperhitungkan jumlah sampel di setiap kelas. Nilai yang sedikit lebih rendah menunjukkan ketidakseimbangan data antara kategori `negatif` dan `positif`.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretasi Contoh Prediksi\n",
        "\n",
        "- **Komentar: \"Indonesia luar biasa!\"**  \n",
        "  Prediksi: **positif**  \n",
        "  Analisis: Model berhasil mengidentifikasi kata-kata seperti *luar biasa* yang biasanya dikaitkan dengan sentimen positif.\n",
        "\n",
        "- **Komentar: \"Keturunan penjajah tidak pantas\"**  \n",
        "  Prediksi: **negatif**  \n",
        "  Analisis: Kata-kata seperti *tidak pantas* memiliki konotasi negatif, sehingga model mampu menangkap konteks ini dengan benar.\n",
        "\n",
        "---\n",
        "\n",
        "### Kesimpulan dan Saran\n",
        "\n",
        "1. **Kesimpulan**:\n",
        "   - Model menunjukkan kinerja yang cukup baik, terutama pada kategori sentimen negatif.\n",
        "   - Ada potensi untuk meningkatkan identifikasi komentar positif, seperti yang terlihat dari precision yang lebih rendah (0.65).\n",
        "\n",
        "2. **Saran Perbaikan**:\n",
        "   - **Imbangi Data**: Jika memungkinkan, tambahkan lebih banyak komentar positif untuk melatih model sehingga distribusi data menjadi lebih seimbang.\n",
        "   - **Pengayaan Stop Words**: Perluas daftar stop words untuk menghapus kata-kata umum yang kurang relevan.\n",
        "   - **Gunakan Teknik NLP Lanjutan**: Gunakan model berbasis *embedding* seperti Word2Vec atau BERT untuk menangkap konteks yang lebih dalam.\n",
        "\n",
        "3. **Praktis untuk Aplikasi**:\n",
        "   - Dengan akurasi **71.25%**, model sudah cukup layak untuk analisis sentimen dasar, seperti memantau opini publik terhadap timnas Indonesia di era STY. Namun, untuk penggunaan di industri, kinerja ini masih perlu ditingkatkan."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}